# Назначение

- Написать программу на Python для сортировки фотографий и видео в папке по образцам обычных и мемных медиа. С помощью Tensorflow модель обучится на мемах медиа и обычных медиа.

Из Видео будет брать N количество кадров через X интервал.

# Инструкция

- Имеются следующие папки:

- Папка с примерами мемных медиа.

- Папка с примерами хороших медиа.

- Папка с файлами для сортировки (выбирается пользователем).

вот код для тренировки модели на фото

import matplotlib.pyplot as plt

import numpy as np

import PIL

import tensorflow as tf


from tensorflow import keras

from tensorflow.keras import layers

from tensorflow.keras.models import Sequential


import pathlib

batch_size =

img_height = 

img_width = 


train_ds = tf.keras.utils.image_dataset_from_directory(

  data_dir,

  validation_split=0.2,

  subset="training",

  seed=123,

  image_size=(img_height, img_width),

  batch_size=batch_size)



val_ds = tf.keras.utils.image_dataset_from_directory(

  data_dir,

  validation_split=0.2,

  subset="validation",

  seed=123,

  image_size=(img_height, img_width),

  batch_size=batch_size)



class_names = train_ds.class_names

print(class_names)



import matplotlib.pyplot as plt


plt.figure(figsize=(10, 10))

for images, labels in train_ds.take(1):

  for i in range(9):

    ax = plt.subplot(3, 3, i + 1)

    plt.imshow(images[i].numpy().astype("uint8"))

    plt.title(class_names[labels[i]])

    plt.axis("off")




for image_batch, labels_batch in train_ds:

  print(image_batch.shape)

  print(labels_batch.shape)

  break



AUTOTUNE = tf.data.AUTOTUNE


train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)

val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)



normalization_layer = layers.Rescaling(1./255)


normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))

image_batch, labels_batch = next(iter(normalized_ds))

first_image = image_batch[0]

# Notice the pixel values are now in `[0,1]`.

print(np.min(first_image), np.max(first_image))



num_classes = len(class_names)


model = Sequential([

  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),

  layers.Conv2D(16, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Conv2D(32, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Conv2D(64, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Flatten(),

  layers.Dense(128, activation='relu'),

  layers.Dense(num_classes)

])



model.compile(optimizer='adam',

              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),

              metrics=['accuracy'])



model.summary()


epochs=10

history = model.fit(

  train_ds,

  validation_data=val_ds,

  epochs=epochs

)



acc = history.history['accuracy']

val_acc = history.history['val_accuracy']


loss = history.history['loss']

val_loss = history.history['val_loss']


epochs_range = range(epochs)


plt.figure(figsize=(8, 8))

plt.subplot(1, 2, 1)

plt.plot(epochs_range, acc, label='Training Accuracy')

plt.plot(epochs_range, val_acc, label='Validation Accuracy')

plt.legend(loc='lower right')

plt.title('Training and Validation Accuracy')


plt.subplot(1, 2, 2)

plt.plot(epochs_range, loss, label='Training Loss')

plt.plot(epochs_range, val_loss, label='Validation Loss')

plt.legend(loc='upper right')

plt.title('Training and Validation Loss')

plt.show()



data_augmentation = keras.Sequential(

  [

    layers.RandomFlip("horizontal",

                      input_shape=(img_height,

                                  img_width,

                                  3)),

    layers.RandomRotation(0.1),

    layers.RandomZoom(0.1),

  ]

)




plt.figure(figsize=(10, 10))

for images, _ in train_ds.take(1):

  for i in range(9):

    augmented_images = data_augmentation(images)

    ax = plt.subplot(3, 3, i + 1)

    plt.imshow(augmented_images[0].numpy().astype("uint8"))

    plt.axis("off")



model = Sequential([

  data_augmentation,

  layers.Rescaling(1./255),

  layers.Conv2D(16, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Conv2D(32, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Conv2D(64, 3, padding='same', activation='relu'),

  layers.MaxPooling2D(),

  layers.Dropout(0.2),

  layers.Flatten(),

  layers.Dense(128, activation='relu'),

  layers.Dense(num_classes, name="outputs")

])



model.compile(optimizer='adam',

              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),

              metrics=['accuracy'])




epochs = 15

history = model.fit(

  train_ds,

  validation_data=val_ds,

  epochs=epochs

)


и скрипт будет отсортировывать в папки mem1 похожие на MEM и в папку not_mem1 похожие на медиа из NOT_MEM


- Обрабатывать только фотографии и видео следующих форматов: JPEG, PNG, BMP, GIF, MP4, AVI, MOV, MKV (указать эти форматы в описании поддерживаемых).


# Формат вывода

- Вывести краткий отчет о количестве файлов, которые были оставлены и перемещены.

добавить DEBUG флаг 


# План действий

- Начать с краткого чеклиста (3-7 концептуальных шагов) того, что будет сделано, чтобы не пропустить важные этапы.

# Валидация результата

- После каждого основного этапа кратко проверить корректность и либо продолжить, либо скорректировать действия в случае ошибки. 


